{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Intro to `pandas`\n", "\n", "We'll explore the Pandas package for simple data handling tasks using geoscience data examples. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Basic Pandas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Introduces the concept of a `DataFrame` in Python. If you're familiar with R, it's pretty much the same idea! Useful cheat sheet [here](https://www.datacamp.com/community/blog/pandas-cheat-sheet-python#gs.59HV6BY)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The main purpose of Pandas is to allow easy manipulation of data in tabular form. Perhaps the most important idea that makes Pandas great for data science, is that it will always preserve **alignment** between data and labels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The most common data structure in Pandas is the `DataFrame`. A 2D structure that can hold various types of Python objects indexed by an `index` array (or multiple `index` arrays). Columns are usually labelled as well using strings.\n", "\n", "An easy way to think about a `DataFrame` is if you imagine it as an Excel spreadsheet.\n", "\n", "Let's define one using a small dataset:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data =  [[2.13, 'sandstone'],\n", "         [3.45, 'limestone'],\n", "         [2.45, 'shale']]\n", "data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Make a `DataFrame` from `data`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.DataFrame(data, columns=['velocity', 'lithology'])\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Accessing the data is a bit more complex than in the numpy array cases but for good reasons"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Adding data\n", "\n", "Add more data (row wise)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[3] = [2.6, 'shale']\n", "df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Add a new column with a \"complete\" list, array or series"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['new_column'] = [\"x\", \"y\", \"z\", \"a\", \"b\"]\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reading a CSV"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pandas also reads files from disk in tabular form ([here](http://pandas.pydata.org/pandas-docs/version/0.20/io.html)'s a list of all the formats that it can read and write). A very common one is CSV, so let's load one!\n", "\n", "The data is the same as used in this study: http://www.kgs.ku.edu/PRS/publication/2003/ofr2003-30/index.html\n", "\n", "From that poster:\n", "\n", "> The Panoma Field (2.9 TCF gas) produces from Permian Council Grove Group marine carbonates and nonmarine silicilastics in the Hugoton embayment of the Anadarko Basin. It and the Hugoton Field, which has produced from the Chase Group since 1928, the top of which is 300 feet shallower have combined to produce 27 TCF gas, making it the largest gas producing area in North America. Both fields are stratigraphic traps with their updip west and northwest limits nearly coincident. Maximum recoveries in the Panoma are attained west of center of the field. Deeper production includes oil and gas from Pennsylvanian Lansing-Kansas City, Marmaton, and Morrow and the Mississippian."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"../data/Panoma_Field_Permian.csv\")\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have some well logs, plus...\n", "\n", "> Two other feature elements derived from other geologic data are geologic constraining variables (GCV), nonmarine-marine (NM-M) and relative position (RPos). NM-M is determined from formation tops and bases and RPos is the position of a particular sample with respect to the base of its respective nonmarine or marine interval. These two important variables help to incorporate geologic knowledge into the variable mix."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n", "import numpy as np\n", "\n", "sns.displot(df['ILD'])"]}, {"cell_type": "markdown", "metadata": {"tags": ["exe"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>Exercise</h3>\n", "\n", "- Create a new column called `ILD_log10` and store in it the log<sub>10</sub> of the values in column `ILD`.\n", "- Make a 'displot' of the new column.\n", "- Check the Pandas documentation [here](http://pandas.pydata.org/pandas-docs/version/0.22/api.html#data-manipulations) and look for a way to determine how many different facies are part of the `DataFrame`.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Inspecting the `DataFrame`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the `DataFrame` with well log information loaded before, we can make a summary using the `describe()` method of the `DataFrame` object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.displot(df'[GR]')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['GR'] = df['GR'].clip(upper=200)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Better descriptions"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can define a Python dictionary to relate facies with the integer label on the `DataFrame`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lithofacies = {1:'sandstone', 2:'c_siltstone', 3:'f_siltstone', 4:'marine_silt_shale',\n", "               5:'mudstone', 6:'wackestone', 7:'dolomite', 8:'packstone', 9:'bafflestone'}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's add a new column with the name version of the facies. There is a `replace()` method on DataFrames and Series, and it takes a dictionary for what to replace with what. So we could also achieve the same thing by passing our dictionary to that."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"Lithofacies\"] = df[\"Facies\"].replace(lithofacies)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Adding more data to the `DataFrame`\n", "\n", "We'd like to augment the DataFrame with some new data, based on some of the existing data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calc_phi_rhob(phind, deltaphi):\n", "    \"\"\"\n", "    Compute phi_RHOB from phi_ND and delta-phi.\n", "    \"\"\"\n", "    return 2 * (phind/100) / (1 - deltaphi/100) - deltaphi/100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calc_rhob(phi_rhob, matrix='sandstone', fluid='brine'):\n", "    \"\"\"\n", "    Computes RHOB from phi_RHOB using some typical values for rho_matrix,\n", "    and rho_fluid. See wiki.aapg.org/Density-neutron_log_porosity\n", "    \"\"\"\n", "    matrixes = {\n", "        'mudstone':   2350,\n", "        'siltstone':  2550,\n", "        'sandstone':  2650,\n", "        'limestone':  2710,\n", "        'dolomite':   2880,\n", "        'anyhydrite': 2980,\n", "        'salt':       2030,\n", "    }\n", "\n", "    fluids = {\n", "        'water':       1000,\n", "        'brine':       1100,\n", "        'heavy oil':   1000,\n", "        'light oil':    800,\n", "        'lng':          650,\n", "    }\n", "    \n", "    rho_matrix = matrixes.get(matrix.lower(), 2650)\n", "    rho_fluid = fluids.get(fluid.lower(), 1100)\n", "    return rho_matrix * (1 - phi_rhob) + rho_fluid * phi_rhob"]}, {"cell_type": "markdown", "metadata": {"tags": ["exe"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>Exercise</h3>\n", "\n", "- Create a new column called `RHOB` and use the functions `calc_phi_rhob` and `calc_rhob` with the appropriate arguments to produce to fill its values. Assume everything is sandstone.\n", "- Check the distribution of the new RHOB values. Sedimentary rocks usually have densities in the range 2000 to 2500 kg/m\u00b3. Some of these seem rather small. Use `df.loc[...]` (with a condition in place of the ellipsis) to make a copy of the DataFrame that only includes the values above some reasonable number, maybe 1500 kg/m\u00b3.\n", "- **Stretch goal:** create a function that processes a row, taking `row` as its only argument. Then use `row['Facies']` to get the matrix (the geological one!) and use that to make the calculation for each row, returning it. Then you can use `df.apply()` with `axis=1` to apply your function to every row and make a new column. Use this dictionary to look up the matrix type:", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lithologies = {1:'sandstone',\n", "               2:'siltstone', 3:'siltstone',\n", "               4:'mudstone', 5:'mudstone',\n", "               6:'wackestone',\n", "               7:'dolomite',\n", "               8:'limestone', 9:'limestone',\n", "              }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# YOUR CODE HERE\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.displot(df['RHOB'].loc[df['RHOB'] > 1000])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visual exploration of the data\n", "\n", "Pandas has a `scatter_matrix()` function, but it's not that pretty."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["_ = pd.plotting.scatter_matrix(df, figsize=(15,15))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can better visualize the properties of each facies and how they compare using Seaborn's `PairPlot`. The library `seaborn` integrates with matplotlib to make these kind of plots easily."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.pairplot(df,\n", "             hue=\"Lithofacies\",\n", "             vars=['GR','RHOB','PE','ILD_log10'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can have a lot of control over all of the elements in the pair-plot by using the `PairGrid` object."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "g = sns.PairGrid(df, hue=\"Lithofacies\", vars=['GR','RHOB','PE','ILD_log10'], height=4)\n", "\n", "g.map_upper(plt.scatter, alpha=0.4)  \n", "g.map_lower(plt.scatter, alpha=0.4)\n", "g.map_diag(plt.hist, bins=20)  \n", "g.add_legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is very clear that it's hard to separate these facies in feature space. Let's simplify a bit:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"Lithology\"] = df[\"Facies\"].replace(lithologies)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mineralogy = {\n", "     1:'siliciclastic',\n", "     2:'siliciclastic', 3:'siliciclastic',\n", "     4:'siliciclastic', 5:'siliciclastic',\n", "     6:'carbonate',\n", "     7:'carbonate',\n", "     8:'carbonate', 9:'carbonate',\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"Mineralogy\"] = df[\"Facies\"].map(mineralogy)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["g = sns.PairGrid(df, hue=\"Lithology\", vars=['GR','RHOB','PE','ILD_log10'], height=4)  \n", "g.map_upper(plt.scatter, alpha=0.4)\n", "g.map_lower(plt.scatter, alpha=0.4)\n", "g.map_diag(plt.hist, bins=20)\n", "g.add_legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["g = sns.PairGrid(df, hue=\"Mineralogy\", vars=['GR','RHOB','PE','ILD_log10'], height=4)  \n", "g.map_upper(plt.scatter, alpha=0.4)\n", "g.map_lower(plt.scatter, alpha=0.4)\n", "g.map_diag(plt.hist, bins=20)\n", "g.add_legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.to_csv(\"../data/training_data.csv\", index=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<hr />\n", "\n", "<p style=\"color:gray\">\u00a92020 Agile Geoscience. Licensed CC-BY.</p>"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "geoml", "language": "python", "name": "geoml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 2}