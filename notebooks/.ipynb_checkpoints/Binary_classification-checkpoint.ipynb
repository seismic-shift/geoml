{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Binary classification\n", "\n", "Let's look at one of the most fundamental types of machine learning task: a binary classification problem. By definition, there are two classes. You can think of them as a 'positive' and 'negative' class.\n", "\n", "First we'll import some data. I'm using an extract from the Rock Property Catalog, https://subsurfwiki.org/wiki/Rock_Property_Catalog"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "\n", "df = pd.read_csv('../data/rocks.csv')\n", "\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Logistic regression\n", "\n", "Let's look at the original binary classifier: logistic regression.\n", "\n", "We will select a single feature, "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X = df[['Rho_n']].values.reshape(-1, 1)\n", "y = df.Lithology.values\n", "\n", "X_train, X_val, y_train, y_val = train_test_split(X, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "def is_sand(y):\n", "    return y=='sandstone'\n", "\n", "plt.scatter(X_train, is_sand(y_train), c=is_sand(y_train), marker='o')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "scaler = StandardScaler()\n", "\n", "scaler.fit(X_train)\n", "\n", "X_train = scaler.transform(X_train)\n", "X_val = scaler.transform(X_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(X_train, is_sand(y_train), c=is_sand(y_train), marker='o')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Train a model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n", "\n", "clf = LogisticRegression()\n", "\n", "clf.fit(X_train, y_train)\n", "\n", "clf.score(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf.score(X_val, y_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "def logistic(x, coef=1):\n", "    return 1 / (1 + np.exp(coef * x))\n", "\n", "# Compute and plot the logistic, so we can see it.\n", "x = np.linspace(-2, 2)\n", "L = logistic(x, np.squeeze(clf.coef_))\n", "plt.figure(figsize=(10, 6))\n", "plt.plot(x, L)\n", "\n", "# Make y-coords for the validation data.\n", "y_val_ = logistic(np.squeeze(X_val), np.squeeze(clf.coef_))\n", "\n", "# Make a prediction.\n", "y_pred = clf.predict(X_val)\n", "\n", "# The TRUE labels.\n", "plt.scatter(X_val[y_val=='sandstone'], y_val_[y_val=='sandstone'], c='firebrick', s=120, label='TRUE sandstone')\n", "plt.scatter(X_val[y_val=='shale'], y_val_[y_val=='shale'], c='mediumblue', s=120, label='TRUE shale')\n", "\n", "# The PREDICTED labels.\n", "plt.scatter(X_val[y_pred=='sandstone'], y_val_[y_pred=='sandstone'], c='gold', s=50, label='PRED sandstone')\n", "plt.scatter(X_val[y_pred=='shale'], y_val_[y_pred=='shale'], c='purple', s=50, label='PRED sandstone')\n", "\n", "# Decoration.\n", "plt.axhline(0.5, color='r', lw=2, alpha=0.5)\n", "plt.text(-2.1, 0.525, 'Cut-off', fontsize=14, c='r')\n", "plt.text(-1.6, 0.492, '\u2195', c='r', size=25, va='center', ha='center')\n", "plt.axvline(0, color='k', lw=2, alpha=0.25)\n", "plt.grid(color='k', alpha=0.15)\n", "plt.title('Logistic regression')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Receiver operating characteristic\n", "\n", "Read more about this here > https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n", "\n", "Basically, we're going to vary the **discrimination threshold** and look at its effect on **sensitivity** (aka *recall* or *true positive rate*) and **specificity** (aka *selectivity* or *true negative rate*), which is equal to 1 \u2013 *false positive rate*.\n", "\n", "We want *sensitivity* and *specificity* to be high."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note that in a binary problem, we're looking at things from the point of view of the 'positive' class, in other words the class with a `y` value of 1. In this case, it's sandstone."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import plot_roc_curve\n", "\n", "fig, ax = plt.subplots(figsize=(6, 6))\n", "plot_roc_curve(clf, X_val, y_val, ax=ax)\n", "ax.plot([0, 1], linestyle='--', lw=2, color='r', label='Chance')\n", "ax.plot([0], [1], 'o', c='C1', ms=10, label='Perfect classifier')\n", "ax.set_xlabel('False Positive Rate (1 - Specificity)')\n", "ax.set_ylabel('True Positive Rate (Sensitivity or Recall)')\n", "ax.grid(c='k', alpha=0.15)\n", "ax.axis('equal')\n", "ax.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Add another feature"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>EXERCISE</h3>\n", "\n", "Let's use V<sub>P</sub> as well. You need to make a new `X`, split out the validation data, and scale the training and validation sets. Then you can train a new Logistic Regression classifier.\n", "\n", "- What score do you get?\n", "- Is it better than using just one feature?\n", "\n", "Finally, make the ROC-AUC plot for this new classifier.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# YOUR CODE HERE\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "It's harder to visualize this thing; we have logistics in each dimension (feature) of the data:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=2, figsize=(15, 4))\n", "\n", "for idx, ax in enumerate(axs):\n", "    x = np.linspace(-5, 5)\n", "    L = logistic(x, np.squeeze(clf.coef_)[idx])\n", "    ax.plot(x, L)\n", "\n", "    y_val_ = logistic(np.squeeze(X_val[:, idx]), np.squeeze(clf.coef_)[idx]) \n", "\n", "    ax.scatter(X_val[y_val=='sandstone', idx], y_val_[y_val=='sandstone'], c='gold', s=100)\n", "    ax.scatter(X_val[y_val=='shale', idx], y_val_[y_val=='shale'], c='indigo')\n", "    ax.axvline(0, color='k', lw=2, alpha=0.25)\n", "    ax.grid(color='k', alpha=0.15)\n", "    ax.set_title(f\"Feature {idx}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It's more natural to look at a decision boundary now:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils import decision_regions\n", "\n", "extent = [-4, 4, -2.5, 2.5]\n", "y_pred, y_all = decision_regions(clf, X_val, y_val, extent, step=0.02)\n", "\n", "plt.imshow(y_all, origin='lower')\n", "plt.colorbar()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 7.5))\n", "plt.imshow(y_all < 0, extent=extent, origin='lower', aspect=1, alpha=0.5)\n", "plt.scatter(*X_val.T, c=is_sand(y_val), s=100, cmap='bwr')\n", "plt.scatter(*X_val.T, c=is_sand(y_pred))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "## A simple SVM model"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>EXERCISE</h3>\n", "\n", "Implement a **support vector machine** (linear or non-linear, it's up to you) and compare its performance \u2014 the accuracy score and the ROC-AUC \u2014 with the logistic regression.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# YOUR CODE HERE\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "Let's visualize the decision surface:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred, y_all = decision_regions(svc, X_val, y_val, extent, step=0.02)\n", "\n", "plt.figure(figsize=(12, 6))\n", "im = plt.imshow(y_all, extent=extent, origin='lower', aspect=1, cmap='bwr_r')\n", "plt.scatter(*X_val.T, c=is_sand(y_val), s=80, cmap='bwr')\n", "plt.scatter(*X_val.T, c=is_sand(y_pred))\n", "plt.colorbar(im)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Again, it's maybe easier to interpret as a boundary:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 7.5))\n", "plt.imshow(y_all < 0., extent=extent, origin='lower', aspect=1, alpha=0.5)\n", "plt.scatter(*X_val.T, c=is_sand(y_val), s=80, cmap='bwr')\n", "plt.scatter(*X_val.T, c=is_sand(y_pred))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Aside** Note that the plotting code here uses the `decision_function` to make the decision surface plot, not the `predict_proba` method. The issue with `predict_proba` is that it sometimes emits P < 0.5 for the selected class. This reflects an issue with the 'Platt scaling' step (see [the documentation](https://scikit-learn.org/stable/modules/svm.html#scores-probabilities)). The catch with the decision function method is that the values it emits cannot be interpreted so easily as probabilities."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Anyway, how does the ROC-AUC look for this model?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(6, 6))\n", "plot_roc_curve(svc, X_val, y_val, ax=ax)\n", "ax.plot([0, 1], linestyle='--', lw=2, color='r', label='Chance')\n", "ax.plot([0], [1], 'o', c='C1', ms=10, label='Perfect classifier')\n", "ax.set_xlabel('False Positive Rate (1 - Specificity)')\n", "ax.set_ylabel('True Positive Rate (Sensitivity or Recall)')\n", "ax.grid(c='k', alpha=0.15)\n", "ax.axis('equal')\n", "ax.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pretty good!\n", " \n", "Both the accuracy score and the ROC-AUC are better than the logistic regression model, so we prefer the support vector machine."]}, {"cell_type": "markdown", "metadata": {}, "source": ["--- \n", "\n", "&copy; 2020 Agile Scientific"]}], "metadata": {"kernelspec": {"display_name": "geoml", "language": "python", "name": "geoml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 4}