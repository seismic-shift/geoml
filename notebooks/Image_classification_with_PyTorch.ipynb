{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Intro to image classification with PyTorch\n", "\n", "**Make sure you look at [`Intro to image classification`](Intro_to_image_classification.ipynb) before coming here.**\n", "\n", "We'll use `Pytorch` on its own in this notebook. See the accompanying notebook, [`Intro to image classification with skorch`](Intro_to_image_classification_with_skorch.ipynb) to see some helper libraries."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The fossil dataset\n", "\n", "Let's generate a workflow to classify images using a CNN.\n", "We'll make use of a collection of functions in `utils.py` to help process the images found in the `data/fossils` folder."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = np.load('../data/fossils/X.npy')\n", "y = np.load('../data/fossils/y.npy')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(X_train[1].reshape(32,32))\n", "plt.colorbar()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Augmentation\n", "\n", "Neural networks like a lot of data. It seems like it should help to increase the size of the dataset... but without having to collect more examples. \n", "\n", "For example, let's flip the image above:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img = X_train[1].reshape(32,32)\n", "\n", "flipped = np.flip(img, axis=1)\n", "\n", "plt.imshow(flipped)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.ndimage import zoom\n", "\n", "cropped = zoom(flipped, 1.1)\n", "\n", "cropped = cropped[1:-2, 1:-2]\n", "\n", "plt.imshow(cropped)"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<div class=\"alert alert-success\">\n", "<h3>Exercise</h3>\n", "\n", "- Write a function to randomly flip and crop each record in `X_train`. (It's okay to use a loop for this.)\n", "- Add your new flipped records to `X_train`, and their labels to `y_train`.\n", "</div>", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# YOUR CODE HERE\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, y_train = augment(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(X_train[499].reshape(32, 32))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train[499]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## `sklearn.neural_network`\n", "\n", "We'll first train a fully connected network. This requires the images to be 1D vectors, like the ones we have, but this means we'll lose some of the 2D spatial properties... Until we use a convolutional neural network!\n", "\n", "See the notebook [Intro to image classification](Intro_to_image_classification.ipynb)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.neural_network import MLPClassifier\n", "from sklearn.metrics import classification_report\n", "\n", "clf = MLPClassifier(hidden_layer_sizes=[100, 24], max_iter=500)\n", "clf.fit(X_train, y_train)\n", "y_pred = clf.predict(X_val)\n", "print(classification_report(y_val, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll start by replicating this in `pytorch`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The `pytorch` approach"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll need to encode the target variable so that the classes are represented by integers. We can use scikit-learn's `LabelEncoder` for that:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder\n", "\n", "encoder = LabelEncoder()\n", "encoder.fit(np.append(y_train, y_val))\n", "\n", "y_train = encoder.transform(y_train)\n", "y_val = encoder.transform(y_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_val"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can make a `Sequential` model and train it."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch import nn\n", "\n", "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n", "device"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the architecture of the network"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FossilNet(torch.nn.Module):\n", "    def __init__(self):\n", "        super(FossilNet, self).__init__()\n", "        self.fc1 = nn.Linear(1024, 100)\n", "        self.act1 = nn.ReLU()\n", "        self.fc2 = nn.Linear(100, 24)\n", "        self.act2 = nn.ReLU()\n", "        self.out = nn.Linear(24, 3)\n", "        # nb Criterion includes softmax.\n", "        \n", "    def forward(self, x):\n", "        z1 = self.fc1(x)\n", "        a1 = self.act1(z1)\n", "        z2 = self.fc2(a1)\n", "        a2 = self.act2(z2)\n", "        z3 = self.out(a2)\n", "        return z3\n", "\n", "model = FossilNet()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now define the loss function, which Torch calls the 'criterion', and the optimizer:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()\n", "optimizer = torch.optim.SGD(model.parameters(),\n", "                            lr = 0.003,\n", "                            weight_decay=0.01,  # L2 regularization.\n", "                            momentum=0.9,\n", "                           )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get the data ready for Torch:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_ = torch.Tensor(X_train).to(device)\n", "y_train_ = torch.Tensor(y_train).type(torch.LongTensor).to(device)\n", "X_val_ = torch.Tensor(X_val).to(device)\n", "y_val_ = torch.Tensor(y_val).type(torch.LongTensor).to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can write the training loop:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 500\n", "vals, trains = [], []\n", "idx = np.arange(0, y_train.size)\n", "\n", "for epoch in range(epochs):\n", "    np.random.shuffle(idx)\n", "    X_train_ = X_train_[idx]\n", "    y_train_ = y_train_[idx]\n", "    \n", "    # Train.\n", "    model.train()\n", "    optimizer.zero_grad()\n", "    y_pred = model(X_train_)  # No batches.\n", "    loss = criterion(y_pred, y_train_)  \n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    # Capture training loss.\n", "    print(f\"Epoch {epoch}/{epochs}: train loss: {loss.item():.3f}\")\n", "    trains.append(loss.item())\n", "\n", "    # Capture validation loss.\n", "    model.eval()\n", "    with torch.no_grad():\n", "        y_pred = model(X_val_)\n", "        loss = criterion(y_pred, y_val_)    \n", "        vals.append(loss.item())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And inspect the history:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(trains, label='Training loss')\n", "plt.plot(vals, label='Validation loss')\n", "plt.xlabel('Epoch')\n", "plt.ylabel('Loss')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["[Validation loss lower than training loss?](https://twitter.com/aureliengeron/status/1110839223878184960)\n", "\n", "This can happen for a few reasons:\n", "\n", "- The training loss is measured during the epoch, while validation loss is measured after it. So the model used in validation is a bit better.\n", "- The training loss includes the regularization penalty, whereas the validation loss does not.\n", "- The validation data might be more predictable than the training data."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_out = model(X_val_).detach().numpy()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But these are not probabilities:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.sum(y_out, axis=-1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.special import softmax\n", "\n", "y_prob = softmax(y_out, axis=-1)\n", "\n", "np.sum(y_prob, axis=-1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That's better!\n", "\n", "Now we can find the argmax for each record:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = np.argmax(y_prob, axis=-1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_val, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Class probability\n", "\n", "The network can emit probabilities. Each instance's vector contains the probability of each class. The argmax of this gives the predicted class.\n", "\n", "In our poor result, the classes are almost equally likely."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import utils\n", "\n", "utils.visualize(X_val, y_val, y_prob,\n", "                ncols=5, nrows=3,\n", "                shape=(32, 32),\n", "                classes=encoder.classes_)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Convolution\n", "\n", "Convolutional networks replace the weights with kernels, and the multiplication step with convolution.\n", "\n", "Let's see what convolution can do to an image."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kernel = np.array([[-1, 0, 1],   # Sobel edge detector\n", "                   [-2, 0, 2],\n", "                   [-1, 0, 1]])\n", "\n", "plt.imshow(kernel)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.signal import convolve2d\n", "\n", "attr = convolve2d(img, kernel.T, mode='valid')\n", "\n", "plt.imshow(attr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here's a nice resource on ConvNets: https://cs231n.github.io/convolutional-networks/"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## A convolutional neural network"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FossilCNN(torch.nn.Module):\n", "    def __init__(self):\n", "        super(FossilCNN, self).__init__()\n", "\n", "        self.conv1 = nn.Conv2d(1, 24, (3, 3), padding=0)\n", "        self.act1 = nn.ReLU()\n", "        self.bn1 = nn.BatchNorm2d(24)\n", "\n", "        self.conv2 = nn.Conv2d(24, 8, (3, 3), padding=0)\n", "        self.act2 = nn.ReLU()\n", "        self.bn2 = nn.BatchNorm2d(8)\n", "\n", "        self.fc = nn.Linear(8 * 28 * 28, 3)\n", "        \n", "        \n", "    def forward(self, x):\n", "        x = self.conv1(x)\n", "        x = self.act1(x)\n", "        x = self.bn1(x)\n", "        x = self.conv2(x)\n", "        x = self.act2(x)\n", "        x = self.bn2(x)\n", "        x = torch.flatten(x, start_dim=1)\n", "        x = self.fc(x)\n", "        return x\n", "\n", "model = FossilCNN()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()\n", "optimizer = torch.optim.SGD(model.parameters(),\n", "                            lr = 0.003,\n", "                            weight_decay=0.01,  # L2 regularization.\n", "                            momentum=0.9,\n", "                           )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_ = torch.Tensor(X_train.reshape(-1, 1, 32, 32)).to(device)\n", "y_train_ = torch.Tensor(y_train).type(torch.LongTensor).to(device)\n", "X_val_ = torch.Tensor(X_val.reshape(-1, 1, 32, 32)).to(device)\n", "y_val_ = torch.Tensor(y_val).type(torch.LongTensor).to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 100\n", "vals, trains = [], []\n", "idx = np.arange(0, y_train.size)\n", "\n", "for epoch in range(epochs):\n", "    np.random.shuffle(idx)\n", "    X_train_ = X_train_[idx]\n", "    y_train_ = y_train_[idx]\n", "    \n", "    # Train.\n", "    model.train()\n", "    optimizer.zero_grad()\n", "    y_pred = model(X_train_)  # No batches.\n", "    loss = criterion(y_pred, y_train_)  \n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    # Capture training loss.\n", "    print(f\"Epoch {epoch}/{epochs}: train loss: {loss.item():.3f}\")\n", "    trains.append(loss.item())\n", "\n", "    # Capture validation loss.\n", "    model.eval()\n", "    with torch.no_grad():\n", "        y_pred = model(X_val_)\n", "        loss = criterion(y_pred, y_val_)    \n", "        vals.append(loss.item())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(trains, label='Training loss')\n", "plt.plot(vals, label='Validation loss')\n", "plt.xlabel('Epoch')\n", "plt.ylabel('Loss')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluation"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "Can you evaluate this model? Write a function to handle everything. You will need to:\n", "\n", "- Compute the model output to make `y_out` (don't forget to detach the tensor).\n", "- Use the `softmax` function to turn the output into probabilities, `y_pred`.\n", "- Get the argmax of the probabilities to make `y_pred`.\n", "- Return `y_prob` and `y_pred`.\n", "- Print a classification report.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict(X, model):\n", "    X = torch.Tensor(X.reshape(-1, 1, 32, 32)).to(device)\n", "    \"\"\"Use `model` to predict on `X`.\"\"\"\n", "    # YOUR CODE HERE\n", "    \n", "    \n", "    return y_prob, y_pred"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["utils.visualize(X_val, y_val, y_prob,\n", "                ncols=5, nrows=3,\n", "                shape=(32, 32),\n", "                classes=encoder.classes_\n", "               )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The kernels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w1 = model.conv1.weight.detach().numpy()\n", "w1.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(nrows=3, ncols=8, figsize=(12, 6))\n", "for w, ax in zip(w1, axs.ravel()):\n", "    ax.imshow(np.sum(w, axis=0))\n", "    ax.axis('off')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w2 = model.conv2.weight.detach().numpy()\n", "\n", "fig, axs = plt.subplots(nrows=1, ncols=8, figsize=(12, 3))\n", "for w, ax in zip(w2, axs.ravel()):\n", "    ax.imshow(np.sum(w, axis=0))\n", "    ax.axis('off')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model persistence and future inference\n", "\n", "The easiest way to save a model is with `torch.save`, but `state_dict` is just an `OrderedDict` so you can do anything you want with it."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.save(model.state_dict(), './fossilnet.pt')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Later, you or someone else can load it. Note that you need to instantiate the model first; the state dictionary does not contain the architecture."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = FossilCNN()\n", "model.load_state_dict(torch.load('./fossilnet.pt'))\n", "model.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from PIL import Image\n", "import io\n", "import requests\n", "\n", "url = \"https://www.treasuremountainmining.com/image/cache/data/2017/08-17/Adam30/EB0817AMMOR4-650x650.jpg\"\n", "r = requests.get(url)\n", "img = Image.open(io.BytesIO(r.content))\n", "img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img = img.convert(mode='L')\n", "img.thumbnail(size=(32, 32))\n", "img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ima = np.asarray(img) / 255\n", "ima.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = torch.Tensor(ima.reshape(-1, 1, 32, 32)).to(device)\n", "\n", "y_prob, y_pred = predict(x, model)\n", "\n", "print(f\"Class {encoder.classes_[y_pred].item().upper():} with p={np.max(y_prob):.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "&copy; 2020 Agile Scientific"]}], "metadata": {"kernelspec": {"display_name": "geocomp", "language": "python", "name": "geocomp"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}