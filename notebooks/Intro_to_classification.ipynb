{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Quick intro to classification\n", "\n", "### We will do this notebook from scratch in class\n", "\n", "First we'll import some data. I'm using an extract from the Rock Property Catalog, https://subsurfwiki.org/wiki/Rock_Property_Catalog"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "\n", "df = pd.read_csv('../data/rocks.csv')\n", "\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df[['Vp', 'Rho_n']].values\n", "y = df.Lithology.values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "plt.scatter(*X.T, c=y=='sandstone')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Could turn that awkward boolean into a function:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def is_sand(y):\n", "    return y == 'sandstone'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## A linear model: SVM\n", "\n", "\n", "### Instructor: briefly explain what an SVM does"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC\n", "\n", "svc = SVC(kernel='linear')\n", "\n", "svc.fit(X, y)\n", "\n", "y_pred = svc.predict(X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(*X.T, c=is_sand(y), s=80, cmap='bwr')\n", "plt.scatter(*X.T, c=is_sand(y_pred))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\n", "\n", "accuracy_score(y, y_pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Plot the decision boundary\n", "\n", "We can visualize the decision boundary, and the class 'regions' using a small function in `utils.py`:\n", "\n", "```python\n", "def decision_regions(clf, X_val, y_val, extent, step=1):\n", "    \"\"\"\n", "    Generate the decision surface of a classifier.\n", "    \"\"\"\n", "    y_pred = clf.predict(X_val)\n", "    x_min, x_max, y_min, y_max = extent\n", "    try:\n", "        x_step, y_step = step\n", "    except TypeError:\n", "        x_step = y_step = step\n", "    xx, yy = np.meshgrid(np.arange(x_min, x_max, x_step),\n", "                         np.arange(y_min, y_max, y_step))\n", "    if hasattr(clf, \"decision_function\"):\n", "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n", "    else:\n", "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n", "    return y_pred, Z.reshape(xx.shape + (-1,))\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Build up from this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils import decision_regions\n", "\n", "extent = [1400, 6500, 1900, 2900]\n", "y_pred, y_all = decision_regions(svc, X, y, extent, step=2)\n", "    \n", "plt.figure(figsize=(15, 9))\n", "plt.imshow(y_all, extent=extent, origin='lower', aspect='auto')\n", "plt.colorbar()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 9))\n", "plt.imshow(y_all <= 0.0, extent=extent, origin='lower', aspect='auto', alpha=0.5)\n", "plt.scatter(*X.T, c=is_sand(y), s=80, cmap='bwr')\n", "plt.scatter(*X.T, c=is_sand(y_pred))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## A non-linear SVM model\n", "\n", "If we employ the **kernel trick** we can fit a nonlinear model. Scikit-learn's `SVC` actually uses this by default:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC\n", "\n", "svc = SVC()  # Default is kernel='rbf'\n", "\n", "svc.fit(X, y)\n", "\n", "y_pred = svc.predict(X)\n", "\n", "plt.scatter(*X.T, c=is_sand(y), s=80, cmap='bwr')\n", "plt.scatter(*X.T, c=is_sand(y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The score is better:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accuracy_score(y, y_pred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred, y_all = decision_regions(svc, X, y, extent, step=2)\n", "    \n", "plt.figure(figsize=(15, 9))\n", "plt.imshow(y_all <= 0.0, extent=extent, origin='lower', aspect='auto', alpha=0.5)\n", "plt.scatter(*X.T, c=is_sand(y), s=80, cmap='bwr')\n", "plt.scatter(*X.T, c=is_sand(y_pred))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Validation\n", "\n", "We should not train the model, then check its accuracy only on that dataset. It's cheating.\n", "\n", "Let's hold out some validation data, or 'blind' data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_val, y_train, y_val = train_test_split(X, y)\n", "\n", "X_train.shape, y_train.shape, X_val.shape, y_val.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's train a model *on only the training data* and validate it properly."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svc = SVC().fit(X_train, y_train)\n", "\n", "y_pred = svc.predict(X_val)\n", "\n", "accuracy_score(y_val, y_pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Standardize the data\n", "\n", "Note that it's a good idea to train SVMs on the Z-scores of your data, i.e. zero mean, StdDev = 1. This ensures that the different scales of the features is not causing a problem. (They are about the same scale in our dataset so the effect is small.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(*X_train.T)\n", "plt.axis('equal')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "scaler = StandardScaler()\n", "\n", "scaler.fit(X_train)\n", "\n", "X_train = scaler.transform(X_train)\n", "X_val = scaler.transform(X_val)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This doesn't change how the data are distributed:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(*X_train.T)\n", "plt.axis('equal')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But the results are better..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svc = SVC(probability=True)\n", "\n", "svc.fit(X_train, y_train)\n", "\n", "svc.score(X_val, y_val)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Draw the decision boundary\n", "\n", "We tried using `mlxtend` here but it is not very accurate."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["extent = [-3.5, 3.5, -3, 3]\n", "y_pred, y_all = decision_regions(svc, X_val, y_val, extent, step=0.02)\n", "    \n", "plt.figure(figsize=(15, 9))\n", "plt.imshow(y_all <= 0.0, extent=extent, origin='lower', aspect='auto', alpha=0.5)\n", "plt.scatter(*X_train.T, c=is_sand(y_train), marker='+', cmap='bwr')\n", "plt.scatter(*X_val.T, c=is_sand(y_val), s=80, cmap='bwr')\n", "plt.scatter(*X_val.T, c=is_sand(y_pred))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Using this model\n", "\n", "If we wanted to use our model now, we should now retrain it on all the data; presumably, this is at least as good as the one trained on the training set, we just don't have a way to check it now."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X)\n", "X_ = scaler.transform(X)\n", "svc = SVC().fit(X_, y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "&copy; 2020 Agile Scientific CC-BY"]}], "metadata": {"kernelspec": {"display_name": "geocomp", "language": "python", "name": "geocomp"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}