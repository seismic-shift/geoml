{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Transfer learning with PyTorch\n", "\n", "This notebook is adapted from [this tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n", "\n", "**You will need to run this notebook in Google Colab. It is very slow to train without a GPU...**\n", "\n", "> [**Open this notebook in Colab**](https://drive.google.com/open?id=1s8k_MRo8AKq5qXE_5XS-7LY-yjzHxC81)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "from torch.optim import lr_scheduler\n", "import numpy as np\n", "import torchvision\n", "from torchvision import datasets, models, transforms\n", "import matplotlib.pyplot as plt\n", "import time\n", "import os\n", "import copy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.__version__, torchvision.__version__"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# If you're on a machine with a CUDA GPU, you can use it.\n", "# torch.cuda.get_device_name(torch.cuda.current_device())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data loading - GDrive"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You will need to add this folder to your Google Drive: https://drive.google.com/drive/folders/14lrVjhBQP7z4eGP4mAQetPC-KD0a0RMo?usp=sharing\n", "\n", "This next cell is for loading the data on Google Drive:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import glob\n", "from google.colab import drive\n", "\n", "drive.mount('/content/gdrive')\n", "\n", "len([f for f in glob.glob(\"/content/gdrive/My Drive/fossilnet/train/*/*.png\")])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from PIL import Image\n", "\n", "img = Image.open('/content/gdrive/My Drive/fossilnet/train/ammonites/00001.png')\n", "img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_dir = '/content/gdrive/My Drive/fossilnet'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data loading - Local\n", "\n", "You can get the data here >> https://swung-data.s3.amazonaws.com/fossilnet/fossilnet-png-224px.zip"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import glob\n", "len([f for f in glob.glob(\"../data/fossils/fossilnet-png-224px/train/*/*\")])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from PIL import Image\n", "\n", "Image.open('../data/fossils/fossilnet-png-224px/train/ammonites/00001.png')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_dir = '../data/fossils/fossilnet-png-224px/'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data augmentation and normalization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_transforms = {\n", "    'train': transforms.Compose([\n", "        transforms.Resize(256),\n", "        transforms.CenterCrop(224),\n", "        transforms.RandomHorizontalFlip(),\n", "        transforms.ToTensor(),\n", "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n", "    ]),\n", "    'val': transforms.Compose([\n", "        transforms.Resize(256),\n", "        transforms.CenterCrop(224),\n", "        transforms.ToTensor(),\n", "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n", "    ]),\n", "}\n", "\n", "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n", "                                          data_transforms[x])\n", "                  for x in ['train', 'val']}\n", "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n", "                                              shuffle=True, num_workers=4)\n", "              for x in ['train', 'val']}\n", "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n", "device"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = image_datasets['train'].classes\n", "class_names"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["no_classes = len(class_names)\n", "no_classes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def imshow(inp, ax=None, title=None):\n", "    \"\"\"Imshow for Tensor.\"\"\"\n", "    inp = inp.numpy().transpose((1, 2, 0))\n", "    mean = np.array([0.485, 0.456, 0.406])\n", "    std = np.array([0.229, 0.224, 0.225])\n", "    inp = std * inp + mean\n", "    inp = np.clip(inp, 0, 1)\n", "    if ax is None:\n", "        fig, ax = plt.subplots(figsize=(8, 2))\n", "        return_ax = False\n", "    else:\n", "        return_ax = True\n", "    im = ax.imshow(inp)\n", "    if title is not None:\n", "        ax.set_title(title)\n", "\n", "    if return_ax:\n", "        return ax\n", "    else:\n", "        return\n", "\n", "# Get a batch of training data\n", "inputs, classes = next(iter(dataloaders['train']))\n", "\n", "# Make a grid from batch\n", "#out = torchvision.utils.make_grid(inputs)\n", "inputs = inputs.to(device)\n", "\n", "fig, axs = plt.subplots(ncols=4, figsize=(16, 4))\n", "for j in range(inputs.size()[0]):\n", "    ax = imshow(inputs.cpu().data[j], ax=axs[j], title=class_names[classes[j]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Retrain the RESNET-18 model\n", "\n", "A residual network is like an ordinary neural network, but with *skip connections*. In other words, a layer might get input not only from the previous layer, but from one or two layers before that. The original ResNet used this strategy with very deep networks with >150 layers; almost 10x deeper than VGG. [Read the original paper.](https://arxiv.org/pdf/1512.03385.pdf)\n", "\n", "### The training function\n", "\n", "This function looks pretty involved at first. Take a minute to read it. Here's what's happening:\n", "\n", "- Loop over the epochs\n", "- In the **train** phase:\n", "  - Call `model.train()` to tell model we're training.\n", "  - Do a forward pass.\n", "  - Do back propagation (compute gradient and optimize).\n", "  - Save the training loss.\n", "- In the **val** phase:\n", "  - Call `model.eval()` to tell the model we're evaluating.\n", "  - Compute the accuracy.\n", "  - If this is the best model so far, remember it."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n", "    since = time.time()\n", "\n", "    # Initialize the 'best so far' variables.\n", "    best_model_wts = copy.deepcopy(model.state_dict())\n", "    best_acc = 0.0\n", "\n", "    # Training loop.\n", "    for epoch in range(num_epochs):\n", "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n", "        print('-' * 10)\n", "\n", "        # Each epoch has a training and validation phase.\n", "        # We need to set the model 'mode'.\n", "        for phase in ['train', 'val']:\n", "            if phase == 'train':\n", "                model.train()\n", "            else:\n", "                model.eval()\n", "\n", "            running_loss = 0.0\n", "            running_corrects = 0\n", "\n", "            # Iterate over data.\n", "            for inputs, labels in dataloaders[phase]:\n", "                inputs = inputs.to(device)\n", "                labels = labels.to(device)\n", "\n", "                # Zero the parameter gradients.\n", "                optimizer.zero_grad()\n", "\n", "                # Forward pass.\n", "                # Track history only if in train.\n", "                with torch.set_grad_enabled(phase == 'train'):\n", "                    outputs = model(inputs)\n", "                    _, preds = torch.max(outputs, 1)\n", "                    loss = criterion(outputs, labels)\n", "\n", "                    # Backprop + optimize only if in train.\n", "                    if phase == 'train':\n", "                        loss.backward()\n", "                        optimizer.step()\n", "                        scheduler.step()\n", "\n", "                # Statistics.\n", "                running_loss += loss.item() * inputs.size(0)\n", "                running_corrects += torch.sum(preds == labels.data)\n", "\n", "            # Accuracy.\n", "            epoch_loss = running_loss / dataset_sizes[phase]\n", "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n", "\n", "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n", "                phase, epoch_loss, epoch_acc))\n", "\n", "            # Deep copy the model if it's the best so far.\n", "            if phase == 'val' and epoch_acc > best_acc:\n", "                best_acc = epoch_acc\n", "                best_model_wts = copy.deepcopy(model.state_dict())\n", "\n", "        print()\n", "\n", "    time_elapsed = time.time() - since\n", "    print('Training complete in {:.0f}m {:.0f}s'.format(\n", "        time_elapsed // 60, time_elapsed % 60))\n", "    print('Best val Acc: {:4f}'.format(best_acc))\n", "\n", "    # Return best model weights.\n", "    model.load_state_dict(best_model_wts)\n", "    return model, train_loss, val_loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Set up the model: tune ALL parameters\n", "\n", "This is where we set up the model. First we must download it (it is 44.7MB and will be cached on your machine). Then we adapt it to our task, set up the loss function and optimizer, and finally set up the learning rate decay."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instantiate the ResNet-18 model.\n", "model_ft = models.resnet18(pretrained=True)\n", "\n", "# Make the fully connection layer fit our task.\n", "num_ftrs = model_ft.fc.in_features\n", "model_ft.fc = nn.Linear(num_ftrs, no_classes)\n", "\n", "# Send to device.\n", "model_ft = model_ft.to(device)\n", "\n", "# Choose loss function.\n", "criterion = nn.CrossEntropyLoss()\n", "\n", "# Observe that *all* parameters are being optimized. (Compared to following example.)\n", "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n", "\n", "# Decay LR by a factor of 0.1 every 7 epochs.\n", "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can actually train the model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_ft, train_loss, val_loss = train_model(model_ft,\n", "                                             criterion,\n", "                                             optimizer_ft,\n", "                                             exp_lr_scheduler,\n", "                                             num_epochs=10,\n", "                                             )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(train_loss)\n", "plt.plot(val_loss)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The training score is much higher than the validation score. The model seems to be somewhat overtrained.\n", "\n", "Let's save the model to a file:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.save(model_ft.state_dict(), '/content/gdrive/My Drive/fossilnet/fossilnet.pt')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualize the results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualize_model(model, num_images=6):\n", "    was_training = model.training\n", "    model.eval()\n", "    images_so_far = 0\n", "    fig, axs = plt.subplots(ncols=6, figsize=(18,3))\n", "\n", "    with torch.no_grad():\n", "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n", "            inputs = inputs.to(device)\n", "            labels = labels.to(device)\n", "\n", "            outputs = model(inputs)\n", "            _, preds = torch.max(outputs, 1)\n", "            \n", "            # Get probabilities\n", "            sm = torch.nn.Softmax()\n", "            probs = sm(outputs)\n", "            argsort = torch.argsort(probs, descending=True)\n", "            \n", "            for j in range(inputs.size()[0]):\n", "                ax = axs[images_so_far]\n", "                images_so_far += 1\n", "                \n", "                actual_class = class_names[labels[j]]\n", "                pred_class = class_names[preds[j]]\n", "                pred_prob = max(probs[j])\n", "                \n", "                # Could also do:\n", "                # pred_class = class_names[argsort[j][0]],\n", "                # pred_prob = probs[j][argsort[j][0]],                    \n", "\n", "                if pred_prob > 99.9e-2:\n", "                    ax.set_title('{}\\n{} {:.3f}'.format(actual_class.upper(),\n", "                                                        pred_class,\n", "                                                        pred_prob,\n", "                                                       ))\n", "                else:\n", "                    ax.set_title('{}\\n{} {:.3f}\\n{} {:.3f}'.format(actual_class.upper(),\n", "                                                        pred_class,\n", "                                                        pred_prob,\n", "                                                        class_names[argsort[j][1]],\n", "                                                        probs[j][argsort[j][1]],\n", "                                                       ))\n", "                ax.set_xticks([])\n", "                ax.set_yticks([])\n", "\n", "                c = 'green' if (actual_class == pred_class) else 'red'\n", "                for spine in ax.spines.values():\n", "                    spine.set_edgecolor(c)\n", "                    spine.set_linewidth(4)\n", "\n", "                ax = imshow(inputs.cpu().data[j], ax=ax)\n", "\n", "                if images_so_far == num_images:\n", "                    model.train(mode=was_training)\n", "                    return\n", "\n", "        model.train(mode=was_training)\n", "\n", "    return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["visualize_model(model_ft)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluating the model\n", "\n", "You will need to step over the data, making predictions, and then comparing them to the validation set labels. \n", "\n", "Most people do the analysis (F1 score, confusion matrix, etc) in `scikit-learn`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Another approach: freeze convolutional layers\n", "\n", "Instead of adjusting the weights in all the layers a little bit, we can choose to only train the last layer."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_conv = torchvision.models.resnet18(pretrained=True)\n", "\n", "# Turn off gradients for faster training.\n", "for param in model_conv.parameters():\n", "    param.requires_grad = False\n", "\n", "# Newly constructed layers have requires_grad=True by default.\n", "num_ftrs = model_conv.fc.in_features\n", "model_conv.fc = nn.Linear(num_ftrs, no_classes)\n", "\n", "# Send to device.\n", "model_conv = model_conv.to(device)\n", "\n", "# Choose the loss function.\n", "criterion = nn.CrossEntropyLoss()\n", "\n", "# Observe that only parameters of final layer are being optimized as\n", "# opposed to before.\n", "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n", "#                                   ^^^^^^\n", "\n", "# Decay LR by a factor of 0.1 every 7 epochs\n", "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_conv, train_loss, val_loss = train_model(model_conv,\n", "                                               criterion,\n", "                                               optimizer_conv,\n", "                                               exp_lr_scheduler,\n", "                                               num_epochs=10,\n", "                                              )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(train_loss)\n", "plt.plot(val_loss)\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["visualize_model(model_conv)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train entire network from scratch\n", "\n", "We'd expect this model to perform poorly, and probably be undertrained."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_new = torchvision.models.resnet18(pretrained=False)  # Not trained is the default.\n", "\n", "# Adapt the fc layer to our task.\n", "num_ftrs = model_new.fc.in_features\n", "model_new.fc = nn.Linear(num_ftrs, no_classes)\n", "\n", "# Send to device.\n", "model_new = model_new.to(device)\n", "\n", "# Choose the loss function.\n", "criterion = nn.CrossEntropyLoss()\n", "\n", "# Observe that only parameters of final layer are being optimized as\n", "# opposed to before.\n", "optimizer_ft = optim.SGD(model_new.parameters(), lr=0.001, momentum=0.9)\n", "\n", "# Decay LR by a factor of 0.1 every 7 epochs\n", "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_new, train_loss, val_loss = train_model(model_new,\n", "                                              criterion,\n", "                                              optimizer_ft,\n", "                                              exp_lr_scheduler,\n", "                                              num_epochs=20,\n", "                                             )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(train_loss)\n", "plt.plot(val_loss)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "geocomp-ml", "language": "python", "name": "geocomp-ml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}}, "nbformat": 4, "nbformat_minor": 2}