{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Machine learning: regression\n", "\n", "We'll try to predict missing well logs using regression.\n", "\n", "The data are from Colorado. We've already loaded the data into a CSV."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from ipywidgets import interact"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["well_logs = '../data/Colorado_well_data.csv'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(well_logs, index_col=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Look at the counts: some of the features have some NaNs. It looks like we won't lose too much data by doing a `dropna`..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.dropna()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["I'd prefer it if the well names were integers not floats."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.Well = df.Well.astype(int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Visual inspection of the data space"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["well = 10\n", "\n", "features = ['CAL', 'SP', 'GR', 'RES', 'NPHI', 'RHOB']\n", "target = 'DT'\n", "\n", "fig, axs = plt.subplots(ncols=len(features)+1, sharey=True, figsize=(8,8))\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax.plot(df.loc[df.Well==well, feature], df.loc[df.Well==well, 'Depth'])\n", "    ax.set_title(feature)\n", "axs[-1].plot(df.loc[df.Well==well, target], df.loc[df.Well==well, 'Depth'], color='red')\n", "axs[-1].set_title(target)\n", "axs[-1].invert_yaxis()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=len(features), figsize=(15, 3))\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax = sns.distplot(df[feature], ax=ax)\n", "    ax.set_title(feature)\n", "    ax.set_yticks([])"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "Make a 'log<sub>10</sub> resisitivity' to deal with the usual RES distribution. Call it `LogRes`.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(df.LogRes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And update the `features` list:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features.remove('RES')\n", "features.append('LogRes')"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "Now look at the gamma ray. Are the very high values coming from one well or from lots of places? \n", "\n", "Decide how to fix the gamma ray. For example, you could:\n", "\n", "- Remove one or more wells with bad GR.\n", "- Remove only the rows with very high values.\n", "- Clip the GR, e.g. using `pd.Series.clip()`.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(df.GR)"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "What is causing the long tail in the NPHI data? Is it spikes or a bad log?\n", "\n", "Decide how best to fix the NPHI, limiting its range to the interval 0 to 0.5.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(df.NPHI)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The distributions should now look something like this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=len(features), figsize=(15, 3))\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax = sns.distplot(df[feature], ax=ax)\n", "    ax.set_title(feature)\n", "    ax.set_yticks([])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Method chaining\n", "\n", "Some people like chaining Pandas' methods into long 'pipelines'. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.query('NPHI > 0.4')  # df.query() is nice... and it returns a df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def log_res(df):\n", "    df['LogRes'] = np.log10(df.RES)\n", "    return df\n", "\n", "dz = (pd.read_csv(well_logs, index_col=0)\n", "        .dropna()\n", "        .pipe(log_res)\n", "        .query('(Well != 3) & (Well != 5)')\n", "     )"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>Exercise</h3>\n", "\n", "This implemented some of our pipeline; can you implement the other things we did?\n", "\n", "- Clip the GR curve, eg at 400 API.\n", "- Fix the NPHI by applying the `fix_nphi` function we already made.\n", "- Apply limits to the NPHI curve as before (0 to 0.5).", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def fix_gamma(df):\n", "    \n", "    # YOUR CODE HERE\n", "\n", "    return df\n", "\n", "\n", "dz = (pd.read_csv(well_logs, index_col=0)\n", "        .dropna()\n", "        .pipe(log_res)\n", "        .query('(Well != 3) & (Well != 5)')\n", "\n", "        # YOUR CODE HERE\n", "\n", "     )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# You should end up with 372611 records.\n", "len(dz) == 372611"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Feature engineering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features = ['GR', 'NPHI', 'RHOB', 'LogRes']\n", "target = 'DT'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Combination features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from itertools import combinations\n", "\n", "combs = combinations(features[:4], 2)\n", "list(combs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["combs = combinations(features[:4], 2)\n", "for f1, f2 in combs:\n", "    new_feature = f'{f1}.{f2}'\n", "    df[new_feature] = df[f1] * df[f2]\n", "    if new_feature not in features:\n", "        features.append(new_feature)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Empirical features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['InvGardner'] = 108 * df.RHOB**4\n", "\n", "if 'InvGardner' not in features:\n", "    features.append('InvGardner')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Smoothed features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['NPHI_smooth'] = 0\n", "for name, group in df.groupby('Well'):\n", "    df.NPHI_Smooth.loc[group.index] = np.convolve(group.NPHI.copy(),\n", "                                                  np.ones(21)/21,\n", "                                                  mode='same')\n", "\n", "if 'NPHI_smooth' not in features:\n", "    features.append('NPHI_smooth')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,3))\n", "df.NPHI[:1000].plot()\n", "df.NPHI_Smooth[:1000].plot()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Nonlinear transformations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['NPHI_sq'] = df.NPHI ** 2.0\n", "\n", "if 'NPHI_sq' not in features:\n", "    features.append('NPHI_sq')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# df['RHOB_sq'] = df.RHOB ** 2.0\n", "# df['RHOB_sr'] = df.RHOB ** 0.5\n", "# Etc."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Split the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.Well.unique()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["How many wells is that?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["len(df.Well.unique())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's start by training on the first six wells only."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n = 8  # We'll come back and change this number."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_train = df[df.Well <= n].copy()\n", "df_val = df[(df.Well >= 70) & (df.Well < 85)].copy()   # 12 wells\n", "df_test = df[df.Well >= 85].copy()  # 10 wells"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Check the distributions\n", "\n", "We'd like to make sure the distributions of the 3 datasets are comparable."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=4, figsize=(15,3))\n", "\n", "for ax, feature in zip(axs, features):\n", "    sns.distplot(df_train[feature], ax=ax)\n", "    sns.distplot(df_val[feature], ax=ax)\n", "    sns.distplot(df_test[feature], ax=ax)\n", "    ax.set_yticklabels([])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Make `X` and `y`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = df_train[features].values\n", "y_train = df_train[target].values\n", "\n", "X_val = df_val[features].values\n", "y_val = df_val[target].values\n", "\n", "X_test = df_test[features].values\n", "y_test = df_test[target].values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Standardize\n", "\n", "It's sensible to standardize the data before linear regression. This transforms all of the features to their Z-scores. That is, we subtract the mean and divide by the standard deviation. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "scaler = StandardScaler()\n", "\n", "scaler.fit(X_train)\n", "\n", "X_train = scaler.transform(X_train)\n", "X_val = scaler.transform(X_val)\n", "X_test = scaler.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train a model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression, Lasso, Ridge\n", "\n", "regr = LinearRegression()\n", "\n", "regr.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_val['DT_pred_LR'] = regr.predict(X_val)\n", "\n", "df_val.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_track(df, idx, *cols):\n", "    fig, ax = plt.subplots(1,1)\n", "    fig.set_size_inches(15,3)\n", "    depths = df.loc[df.Well == idx, 'Depth']\n", "    for col in cols:\n", "        ax.plot(depths, df.loc[df.Well == idx, col], lw=1.5, label=col)\n", "    ax.set_xlim(1300, 2400)\n", "    ax.set_ylim(40, 140)\n", "    plt.legend()\n", "    return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@interact(idx=(df_val.Well.unique().min(), df_val.Well.unique().max(), 1))\n", "def plot_different_wells(idx=76):\n", "    plot_track(df_val, idx, 'DT', 'DT_pred_LR')\n", "    return"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Evaluation metrics\n", "\n", "Two convenient ways to evaluate regressions are with the $R^2$ score..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import r2_score, mean_squared_error\n", "\n", "r2_score(df_val.DT, df_val.DT_pred_LR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And the RMS error:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.sqrt(mean_squared_error(df_val.DT, df_val.DT_pred_LR))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Other linear regressors\n", "\n", "Linear regression by ordinary least squares (`LinearRegression` model) tries to find the best weights or coefficients, and their values are unconstrained. \n", "\n", "Sometimes we want to constrain them a little, to try to make a 'simpler' model and prevent overfitting.\n", "\n", "For example, `Ridge` adds an L2 penalty to the weights. In other words, it tries to keep the weight vector as small ('short', or low magnitude) as possible. In geophysics, this is sometimes referred to as [Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr_coef = regr.coef_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regr = Ridge(alpha=1.0)\n", "\n", "regr.fit(X_train, y_train)\n", "\n", "df_val['DT_pred_L2'] = regr.predict(X_val)\n", "\n", "print('r2_score ', r2_score(df_val.DT, df_val.DT_pred_L2))\n", "print('RMS error', np.sqrt(mean_squared_error(df_val.DT, df_val.DT_pred_L2)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["l2_coef = regr.coef_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alternatively, we can try to minimize the L1 norm of the weight vector. This tries to keep as many coefficients as possible at 0. If you believe there to be only a few important features, it would be sensible to try this.\n", "\n", "This regressor is called [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regr = Lasso(alpha=1.0)\n", "\n", "regr.fit(X_train, y_train)\n", "\n", "df_val['DT_pred_L1'] = regr.predict(X_val)\n", "\n", "print('r2_score ', r2_score(df_val.DT, df_val.DT_pred_L1))\n", "print('RMS error', np.sqrt(mean_squared_error(df_val.DT, df_val.DT_pred_L1)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["l1_coef = regr.coef_  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for coef, data in {'lr': lr_coef, 'l2': l2_coef, 'l1': l1_coef}.items():\n", "    plt.plot(data, lw=2, label=coef)\n", "plt.axhline(0, c='k', lw=1)\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Check error distribution\n", "\n", "In particular, we want to check that:\n", "\n", "1. The errors are normally distributed with a zero mean.\n", "1. The variance of the errors is not correlated with the parameters.\n", "\n", "There's some good advice about normality tests in [this article by Jason Brownlee](https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/).\n", "\n", "First we'll just use visual inspection:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["residuals = df_val['DT_pred_LR'] - df_val['DT']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(residuals)\n", "plt.axvline(0, color='k', lw=0.5)\n", "plt.axvline(residuals.mean(), color='r')\n", "plt.grid(color='k', alpha=0.15)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Normality: QQ plot\n", "\n", "A quantile-quantile plot generates an idealized distribution, in this case a Gaussian. The idealized samples are divided into quantiles, then each data point in the sample is paired with a similar member from the idealized distribution. The line `'s'` represents the standard 'normal' distribution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from statsmodels.graphics.gofplots import qqplot\n", "\n", "qqplot(residuals, line='s')\n", "plt.axvline(0, color='k', lw=0.5)\n", "plt.axhline(0, color='k', lw=0.5)\n", "plt.grid(color='k', alpha=0.15)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Normality: Shapiro&ndash;Wilk test\n", "\n", "Not convinced about this &mdash; seems like most large samples don't fit. `p` just gets very small."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.stats import shapiro\n", "\n", "res_shuf = residuals.values\n", "np.random.shuffle(res_shuf)\n", "\n", "stat, p = shapiro(res_shuf[:500])\n", "print(f'Statistics = {stat:.3f}, p = {p:.3f}')\n", "\n", "alpha = 0.05\n", "if p > alpha:\n", "    print('Sample looks Gaussian (fail to reject H0)')\n", "else:\n", "    print('Sample does not look Gaussian (reject H0)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Homoscedasticity: visual inspection\n", "\n", "We want to check that the variance of the errors is not correlated with our parameters.\n", "\n", "If they are correlated (if the plots below show points with narrow spread at one end and wide at the other), then there are nonlinearities in the data that are not captured by the model. It could be that outliers are skewing the distribution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=4, figsize=(16,4), sharey=True)\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax.scatter(df_val[feature], residuals, s=1, alpha=0.1)\n", "    ax.set_xlabel(feature)\n", "    ax.axhline(0, color='k', lw=0.5)\n", "    ax.grid(color='k', alpha=0.15)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Coefficients\n", "\n", "**If the features have been standardized**, then we can interpret the learned coefficients (or parameters, or weights if you prefer) as feature importance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.set_printoptions(suppress=True)\n", "regr.coef_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regr.intercept_"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "Can you make a list of the features ordered by their coefficients?", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## `statsmodels`: Confidence interval and prediction interval\n", "\n", "Often, we'd like to know the range of possible responses. Scikit-learn is for predictions, and doesn't have a lot of tools for in-sample statistics. For that, we need to use `statsmodels` or some other statistical package. \n", "\n", "Check out [this notebook by Matteo Niccoli](https://github.com/mycarta/Data-science-tools-petroleum-exploration-and-production/blob/master/Python/notebooks/Python_OLS_confidence_interval_and_prediction_interval.ipynb)\n", "\n", "For regression of a variable y on a single independent variable x, you can also use `seaborn`, e.g. [see this help page](https://seaborn.pydata.org/tutorial/regression.html)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import statsmodels.api as sm\n", "from statsmodels.stats.outliers_influence import summary_table\n", "\n", "X_train_s = sm.add_constant(X_train)  # Intercept not included by default.\n", "\n", "reg = sm.OLS(y_train, X_train_s).fit()  # Fit the model.\n", "\n", "_, data, columns = summary_table(reg, alpha=0.05)  # Get the results, including CI, PI.\n", "\n", "ds = pd.DataFrame(data, columns=map(lambda s: s.replace('\\n', ' '), columns))\n", "\n", "ds.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Confidence interval** is the range we expect the **mean** to be within, for a given confidence level (default is `alpha = 0.5` or a confidence level of 95%). \n", "\n", "**Prediction interval** is the range we expect **a given observation** to be within at that confidence level.\n", "\n", "Let's also check the predictive power of this model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_val_s = sm.add_constant(X_val)\n", "\n", "df_val['DT_pred_SM'] = reg.predict(X_val_s)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These should be more or less exactly like the OLS results from `sklearn`..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r2_score(df_val.DT, df_val.DT_pred_SM)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.sqrt(mean_squared_error(df_val.DT, df_val.DT_pred_SM))"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>Exercise: Try using a deep neural network</h3>\n", "\n", "Have a go at doing this regression using `sklearn`'s neural network, or using TensorFlow if you prefer. See if you can beat the linear regression.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.neural_network import MLPRegressor\n", "\n", "# YOUR CODE HERE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@interact(idx=(df_val.Well.unique().min(), df_val.Well.unique().max(), 1))\n", "def plot_different_wells(idx=76):\n", "    plot_track(df_val, idx, 'DT', 'DT_pred_LR', 'DT_pred_NN', 'DT_pred_TF')\n", "    return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "geocomp-ml", "language": "python", "name": "geocomp-ml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}}, "nbformat": 4, "nbformat_minor": 2}