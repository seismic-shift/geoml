{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Intro to PyTorch for classification tasks\n", "\n", "We'll use Pytorch together with supporting libraries `tensorlayers` and `skorch` to train a regressor that will map synthetic accoustic seismic waveforms and their corresponding velocity profiles. The dataset was put together by Lukas Mosser and is hosted on github here: [https://github.com/LukasMosser/SNIST](https://github.com/LukasMosser/SNIST)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import datetime\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings\n", "warnings.simplefilter(action='ignore', category=FutureWarning)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["urls = [\n", "        'https://raw.githubusercontent.com/LukasMosser/SNIST/master/data/train/train_amplitudes.npy',\n", "        'https://raw.githubusercontent.com/LukasMosser/SNIST/master/data/train/train_velocities.npy',\n", "        'https://raw.githubusercontent.com/LukasMosser/SNIST/master/data/test/test_amplitudes.npy',\n", "        'https://raw.githubusercontent.com/LukasMosser/SNIST/master/data/test/test_velocities.npy',\n", "        'https://raw.githubusercontent.com/LukasMosser/SNIST/master/data/test/test_amplitudes_noise_1.npy',\n", "        'https://raw.githubusercontent.com/LukasMosser/SNIST/master/data/test/test_amplitudes_noise_2.npy'\n", "    ]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Numpy allows you to point at URL data sources. It'll take care of downloading them and keeping reference of where they are with respect to a root folder specified by the user."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ds = np.DataSource('../data/')\n", "\n", "train_amplitudes = np.load(ds.open(urls[0], mode='rb'))\n", "train_velocities = np.load(ds.open(urls[1], mode='rb'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(train_amplitudes[0], aspect=0.06)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(train_velocities[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's define some dataset parameters. Note that these come from the [SNIST](https://github.com/LukasMosser/SNIST) properties."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N_train = 600    # Number of total training examples\n", "N_val = 150      # Number of samples used for validation\n", "N_samples = 271  # Number of samples in time\n", "N_recorders = 20 # Number of recording stations\n", "N_target = 9     # Number of layers in the target velocity model\n", "N_z = 360        # Number of grid blocks in z-dimension (only used for visualisation)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now some neural network parameters:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr = 1e-2                  # Learning rate\n", "batch_size = N_train-N_val # Batchsize used in training - do full batch evaluation because of small data\n", "N_epochs = 200             # Number of epochs to train for"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch import nn\n", "\n", "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n", "device"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Number of neurons in hidden layer\n", "n_hidden = 50\n", "\n", "# Setup a sequential network\n", "model = nn.Sequential(\n", "            nn.Linear(N_recorders*N_samples, n_hidden),\n", "            nn.Sigmoid(),\n", "            nn.Linear(n_hidden, N_target),\n", "        )\n", "\n", "model.to(device)\n", "print(model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We need to make sure the inputs are standarized:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_mean, train_std = train_amplitudes.mean(), train_amplitudes.std()\n", "train_vel_max = train_velocities.max()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = train_amplitudes - train_mean\n", "X /= train_std\n", "\n", "y = train_velocities / train_vel_max\n", "\n", "X_train = X[:-N_val]\n", "y_train = y[:-N_val]\n", "\n", "\n", "X_test = X[N_train-N_val:]\n", "y_test = y[N_train-N_val:]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's confirm that the shapes of these matrices are OK:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train.shape, y_train.shape, X_test.shape, y_test.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We want to make the training data to be 1D to be allowed through this fully connected neural network."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = X_train.reshape((N_train-N_val, N_samples*N_recorders))\n", "X_test = X_test.reshape((N_val, N_samples*N_recorders))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can implement "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch.utils.data as utils\n", "\n", "X_train_ = torch.tensor(X_train, dtype=torch.float).to(device)\n", "y_train_ = torch.tensor(y_train, dtype=torch.float).to(device)\n", "\n", "traindata = utils.TensorDataset(X_train_, y_train_)\n", "trainloader = utils.DataLoader(traindata)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch.optim as optim\n", "\n", "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n", "criterion = nn.MSELoss()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 10\n", "\n", "for epoch in range(epochs):\n", "    epoch_loss = 0.0\n", "    for i, data in enumerate(trainloader):\n", "        inputs, labels = data\n", "        optimizer.zero_grad()\n", "        outputs = model(inputs)\n", "        loss = criterion(outputs, labels)\n", "        loss.backward()\n", "        optimizer.step()\n", "        epoch_loss += loss.item()\n", "    print(f\"# {epoch+1}  Loss {epoch_loss}\")\n", "print('Finished Training')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can make predictions with the trained model:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test_ = torch.tensor(X_test, dtype=torch.float).to(device)\n", "y_test_ = torch.tensor(y_test, dtype=torch.float).to(device)\n", "\n", "valdata = utils.TensorDataset(X_test_, y_test_)\n", "valloader = utils.DataLoader(valdata)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = np.array([model(xi).cpu().detach().numpy() for xi, yi in valloader])\n", "y_pred = np.squeeze(y_pred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(y_pred[0], label='Predicted velocity')\n", "plt.plot(y_test[0], label='True velocity')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can save the model like this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.save(model.state_dict(), 'model.ckpt')"]}, {"cell_type": "markdown", "metadata": {"tags": ["exe"]}, "source": ["<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n", "<h3>Exercise</h3>\n", "\n", "- Create a training function to perform the whole training loop. For now, it should receive as parameters `X_train` and `y_train` and return a trained model\n", "- Put as parameter the number of neurons that are part of the single hidden layer and see how the training performance (loss) varies\n", "- Add more hidden layers and train models with different network configurations", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A couple of extra libraries can help the process of making neural networks with Pytorch:\n", "- `Torchlayers`: Figures out dimensionality of input and output of each layer\n", "- `skorch`: Provides a `scikit-learn` compatible object from a `Pytorch` network to incorporate in scikit-learn workflows"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torchlayers as tl\n", "from skorch import NeuralNetRegressor"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A model can now be created like this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define the architecture of the network\n", "net_arch = torch.nn.Sequential(\n", "    tl.Linear(50),  # specify ONLY out_channels\n", "    tl.Sigmoid(),  # activation from first hidden layer\n", "    tl.Linear(10),  # specify ONLY out_channels\n", "    tl.Sigmoid(), # activation from second hidden layer\n", "    tl.Linear(N_target),  # Output for 10 classes\n", ")\n", "\n", "# Build the network\n", "net = tl.build(net_arch, torch.randn(1, *X_train[0].shape)) # torchlayers needs an input example to figure out the internal dimensions of the network"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can create the scikit-learn compatible object:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = NeuralNetRegressor(\n", "    net,\n", "    max_epochs=10,\n", "    lr=0.01,\n", ")\n", "\n", "model.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_proba = model.predict(X_test)\n", "y_proba[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(y_pred[0], label='Predicted velocity')\n", "plt.plot(y_test[0], label='True velocity')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Convolutional Neural Networks\n", "What'as a Convolutional Neural Network?\n", " - Keep these cheatsheets at hand: https://github.com/afshinea/stanford-cs-230-deep-learning\n", " \n", "![alt text](../images/convolution-layer-a.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## What's max-pooling?\n", "![alt text](../images/max-pooling-a.png)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = train_amplitudes - train_mean\n", "X /= train_std\n", "\n", "y = train_velocities / train_vel_max\n", "\n", "X_train = X[:-N_val]\n", "y_train = y[:-N_val]\n", "\n", "\n", "X_test = X[N_train-N_val:]\n", "y_test = y[N_train-N_val:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# torch.nn and torchlayers can be mixed easily\n", "net_arch = torch.nn.Sequential(\n", "    tl.Conv(32),  # specify ONLY out_channels\n", "    nn.ReLU(),  # use torch.nn wherever you wish\n", "    tl.GlobalMaxPool(),  # Known from Keras\n", "    tl.Linear(5), # Add a fully connected hidden layer\n", "    tl.ReLU(), # Activate the hidden layer\n", "    tl.Linear(9),  # Output for target linear output\n", ")\n", "\n", "net = tl.build(net_arch, torch.randn(1, *X_train[0].shape))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = NeuralNetRegressor(\n", "    net,\n", "    max_epochs=10,\n", "    lr=0.01,\n", ")\n", "\n", "model.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_proba = model.predict(X_test)\n", "y_proba[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(y_pred[0], label='Predicted velocity')\n", "plt.plot(y_test[0], label='True velocity')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model persistence\n", "\n", "The easiest way to save a model is to `pickle` the trained model object."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pickle\n", "\n", "# saving\n", "with open('torch_regressor.pkl', 'wb') as f:\n", "    pickle.dump(model, f)\n", "\n", "# loading\n", "with open('torch_regressor.pkl', 'rb') as f:\n", "    model = pickle.load(f)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.predict(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "geoml", "language": "python", "name": "geoml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 4}