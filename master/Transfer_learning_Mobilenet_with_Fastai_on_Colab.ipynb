{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"geocomp-ml","language":"python","name":"geocomp-ml"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Transfer_learning_Mobilenet_with_Fastai.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"cEd-dyysZTmc","colab_type":"text"},"source":["# Transfer learning application using `fastai`\n","\n","Libraries built on top of `pytorch` such as `fastai` provide easy ways of using pre-trained models. The next snippets of code use a pre-trained `mobilenet` network and re-trains the last layer to classify our fossil dataset."]},{"cell_type":"code","metadata":{"id":"kDL_mBEhZTmf","colab_type":"code","colab":{}},"source":["from fastai.vision import ImageDataBunch, models, accuracy, cnn_learner, ClassificationInterpretation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9hqirNxNZTnY","colab_type":"text"},"source":["Load the data using the `ImageDataBunch` object. Its method `from_folder` needs as an argument the parent directory where the images are. Note that it'll infer classes and will take care of processing all images so that they're consistent for training. You can also specify the location of a validation dataset in that directory. There are various other `from_` methods available. Check them out in the `fastai` [docs](https://docs.fast.ai/vision.data.html#ImageDataBunch)."]},{"cell_type":"markdown","metadata":{"id":"QoqipZ-OaXwq","colab_type":"text"},"source":["## Data loading - Local\n","\n","You can get the data here >> https://swung-data.s3.amazonaws.com/fossilnet/fossilnet-png-224px.zip"]},{"cell_type":"code","metadata":{"id":"fXmnHE_baa6U","colab_type":"code","colab":{}},"source":["import glob\n","\n","len([f for f in glob.glob(\"../data/fossils/fossilnet-png-224px/train/*/*\")])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FqtPlJRTabd5","colab_type":"code","colab":{}},"source":["from PIL import Image\n","\n","Image.open('../data/fossils/fossilnet-png-224px/train/ammonites/00001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V52LTb64abzD","colab_type":"code","colab":{}},"source":["data_dir = '../data/fossils/fossilnet-png-224px/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-d8vUMG8Zi1y","colab_type":"text"},"source":["## Data loading - GDrive\n","\n","You will need to add this folder to your Google Drive: https://drive.google.com/drive/folders/14lrVjhBQP7z4eGP4mAQetPC-KD0a0RMo?usp=sharing\n","\n","This next cell is for loading the data on Google Drive:"]},{"cell_type":"code","metadata":{"id":"Y9t92jetZmOE","colab_type":"code","colab":{}},"source":["import glob\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","len([f for f in glob.glob(\"/content/gdrive/My Drive/fossilnet/train/*/*.png\")])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xgr3JlUmZTna","colab_type":"text"},"source":["This target directory contains:"]},{"cell_type":"code","metadata":{"id":"zMwQz0iTZTnc","colab_type":"code","colab":{}},"source":["ls \"/content/gdrive/My Drive/fossilnet/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YuPskz6pZTnm","colab_type":"text"},"source":["Inside each of those there's a per-class folder containing al the image files:"]},{"cell_type":"code","metadata":{"id":"ViRibV_EZTno","colab_type":"code","colab":{}},"source":["ls \"/content/gdrive/My Drive/fossilnet/train\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-za0VSXaPJa","colab_type":"code","colab":{}},"source":["from PIL import Image\n","\n","img = Image.open('/content/gdrive/My Drive/fossilnet/train/ammonites/00001.png')\n","img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"41u-UTDsan-t","colab_type":"code","colab":{}},"source":["data_dir = \"/content/gdrive/My Drive/fossilnet/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Hvky3dYZTnz","colab_type":"text"},"source":["## Make a `fastai` dataset\n","\n","We can instantiate the `ImageDataBunch` object to collect all images like this:"]},{"cell_type":"code","metadata":{"id":"PxFxmJRFZTn1","colab_type":"code","colab":{}},"source":["data = ImageDataBunch.from_folder(data_dir,\n","                                  valid='val',\n","                                  size=128,\n","                                  classes=['ammonites', 'plants', 'fishes', 'trilobites'],\n","                                 )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LwYeAA8dZTn-","colab_type":"text"},"source":["We can create a \"learner\" object using a pre-trained network using the `cnn_learner` function. Note that this is where we specify what trained network we want to use and what metrics we want to track. Check out what other parameters and options there are in the fastai [docs](https://docs.fast.ai/vision.learner.html)"]},{"cell_type":"code","metadata":{"id":"78R8AJMpaJ7r","colab_type":"code","colab":{}},"source":["dir(models)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jwPYzNf2ZToA","colab_type":"code","colab":{}},"source":["cnn = cnn_learner(data, models.mobilenet_v2, metrics=accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rk8HscKmZToJ","colab_type":"text"},"source":["Finally, train the learner. It'll take a few minutes."]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"CnVtG9w8ZToL","colab_type":"code","colab":{}},"source":["cnn.fit(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jygutBWvZToX","colab_type":"code","colab":{}},"source":["from fastai.basics import DatasetType\n","\n","cnn.show_results(DatasetType.Train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t4n-vprzZToh","colab_type":"text"},"source":["## Inference\n","\n","We can make a prediction on a single image. The model 'knows' that it has to resize the image, etc."]},{"cell_type":"code","metadata":{"id":"4aX2fv63ZToi","colab_type":"code","colab":{}},"source":["from fastai.vision import open_image\n","import requests\n","import io"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7Cy0lCcZTor","colab_type":"code","colab":{}},"source":["r = requests.get(\"https://geology.com/articles/green-river-fossils/fossil-fish-lg.jpg\")\n","    \n","item = open_image(io.BytesIO(r.content))\n","\n","cnn.predict(item)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFAA2PY7ZToz","colab_type":"code","colab":{}},"source":["cnn.data.classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FlH958d1ZTpB","colab_type":"text"},"source":["## More evaluation tools\n","\n","`fastai` also provides supporting objects to asses the quality of the predictions. Below, we'll use it to visualize the predictions of the worst performing classifications based on the training loop we ran above"]},{"cell_type":"code","metadata":{"id":"muCKYY2EZTpD","colab_type":"code","colab":{}},"source":["interp = ClassificationInterpretation.from_learner(cnn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2k13aMa4ZTpP","colab_type":"code","colab":{}},"source":["interp.confusion_matrix()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKFj1Mz3ZTpY","colab_type":"code","colab":{}},"source":["interp.plot_top_losses(9, figsize=(12,12))\n","\n","# 'Probability' is the P of the actual class."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gB8lF_gcZTph","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}