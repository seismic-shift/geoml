{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# Make sure we can see all of the model details.\n",
    "sklearn.set_config(print_changed_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to image classification with Scikit-Learn\n",
    "\n",
    "What about when the records are images? How can we make a machine learning model from those?\n",
    "\n",
    "This notebook only uses `scikit-learn`; later we'll solve this problem with neural networks too.\n",
    "\n",
    "We're also going to cheat a bit by loading pre-processed NumPy arrays. Getting images into this format is not too hard, but it can be a little fiddly if they are all very different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('../data/fossils/X.npy')\n",
    "y = np.load('../data/fossils/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X` is an image of size 32 &times; 32 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[190].reshape(32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Split the data so that 15% of the images go into a **validation** set called `X_val` and `y_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "We'd really like a lot of data (especially if we're going to train a neural net!). It seems like it should help to increase the size of the dataset... but without having to collect more examples. \n",
    "\n",
    "For example, let's flip the image above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "img = X_train[1].reshape(32,32)\n",
    "\n",
    "flipped = np.flip(img, axis=1)\n",
    "\n",
    "plt.imshow(flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "cropped = zoom(flipped, 1.1)\n",
    "\n",
    "cropped = cropped[1:-2, 1:-2]\n",
    "\n",
    "plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Exercise</h3>\n",
    "\n",
    "- Write a function to randomly flip and crop each record in `X_train`. (It's okay to use a loop for this.)\n",
    "- Add your new flipped records to `X_train`, and their labels to `y_train`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a 'shallow' model\n",
    "\n",
    "Even in an image classification task, you should start with a shallow learning model. This will give you something to beat with a neural network (if you can!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Implement a random forest classifier and predict the labels for the validation set. You should get performance around 65% weighted average F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE (about 4 lines of code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking more closely at validation\n",
    "\n",
    "Here's the first validation example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_val[0].reshape(32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong! (Note: You'll need to use `random_state=42` in both the test split and the classifier for this to work out for sure!)\n",
    "\n",
    "Let's look at the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = clf.predict_proba(X_val)\n",
    "\n",
    "y_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the classifier's second guess would have been correct.\n",
    "\n",
    "Let's look at how we did on several examples. To use my visualization function, we need integer-encoded labels, not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "\n",
    "# Encode both the train and val labels.\n",
    "y_train_enc = encoder.transform(y_train)\n",
    "y_val_enc = encoder.transform(y_val)\n",
    "\n",
    "y_val_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to copy the `utils.py` file from the `master` folder to the `notebooks` folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.visualize(X_val, y_val_enc, y_prob,\n",
    "                ncols=5, nrows=3, shape=(32, 32),\n",
    "                classes=clf.classes_, cutoff=0.5\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "Convolutional networks replace the weights with kernels, and the multiplication step with convolution.\n",
    "\n",
    "Let's see what convolution can do to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, 0, 1],   # Sobel edge detector\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "plt.imshow(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "attr = convolve2d(img, kernel, mode='valid')\n",
    "\n",
    "plt.imshow(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a nice resource on ConvNets: https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Usually we'll stop this notebook here.**\n",
    "\n",
    "---\n",
    "\n",
    "## Dimensionality reduction\n",
    "\n",
    "In high-dimensional datasets (i.e. ones with a lot of features), sometimes it helps to reduce the number of dimensions.\n",
    "\n",
    "### Principal component analysis (PCA)\n",
    "\n",
    "Let's try PCA; it works just like any other `sklearn` model, except that it's **unsupervised** so the `fit` step does not need to see the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_2 = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X_train_2.T, c=y_train_enc, )\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the components themselves. They are directions in our original feature space -- so they can be interpreted as feature vectors.\n",
    "\n",
    "We can call these **'eigenfossils'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ticks = {'xticks': [], 'yticks': []}\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(8, 4), subplot_kw=no_ticks)\n",
    "for i, (ax, comp) in enumerate(zip(axs, pca.components_)):\n",
    "    ax.imshow(comp.reshape(32, 32))\n",
    "    ax.set_title(f\"Component {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit more interesting with more components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50).fit(X_train)\n",
    "\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15, 10), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for i, (ax, comp) in enumerate(zip(axs.ravel(), pca.components_)):\n",
    "    ax.imshow(comp.reshape(32, 32))\n",
    "    ax.set_title(f\"Component {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-statistic neighbourhood embedding (t-SNE)\n",
    "\n",
    "We can also try t-SNE, which typically does better than PCA for visualizing a dataset in two dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "X_train_tsne = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X_train_tsne.T, c=y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on reduced data\n",
    "\n",
    "We'll just use PCA here, because t-SNE is not guaranteed to be a metric space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "- Create a PCA decomposition with 50 components and transform `X_train` and `X_val`.\n",
    "- Train a new model on the transformed data, and validate on the transformed validation data.\n",
    "- Do you get a better result than before?\n",
    "\n",
    "**Stretch goal:** put the PCA transformer and the estimator into a pipeline and use cross-validation grid-search to find the optimal number of principal components to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_train)\n",
    "X_train_50 = pca.transform(X_train)\n",
    "X_val_50 = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_50, y_train)\n",
    "y_pred = clf.predict(X_val_50)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pca = PCA()\n",
    "rfc = RandomForestClassifier(min_samples_leaf=3)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('rfc', rfc)])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': np.logspace(0.5, 3, 6, dtype=int),\n",
    "    'rfc__max_depth': [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipe, param_grid, n_jobs=6, verbose=5)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "y_pred = cv.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "Conclusion: it's not much better than the original model. Oh well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more thing...\n",
    "\n",
    "It's fun to play with adding principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200, whiten=True)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(instance=(0, 498, 1), components=(1, 201, 5))\n",
    "def show(instance, components):\n",
    "    img = (X_train_pca[instance] * pca.components_.T).T\n",
    "    _, ax = plt.subplots(figsize=(8, 8), subplot_kw=no_ticks)\n",
    "    im = np.sum(img[:components], axis=0)\n",
    "    ax.imshow(im.reshape(32, 32))\n",
    "    ax.set_title(f\"First {components} components of instance {instance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction on MNIST Handwritten Digits dataset\n",
    "\n",
    "Just for fun, let's compare PCA with t-SNE on (a subset of) the famous MNIST digits dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits.data[234].reshape(8, 8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Can you adapt the code above to make (1) the 2-component PCA decomposition and (2) the 2-component t-SNE manifold? Then try crossplotting the 2 components for each decomposition, as we did before. Which one is better?\n",
    "\n",
    "Give it a try before you scroll down for the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(digits.data)\n",
    "digits_pca = pca.transform(digits.data)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "digits_tsne = tsne.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 6), subplot_kw=no_ticks)\n",
    "axs[0].set_title('PCA')\n",
    "axs[0].scatter(*digits_pca.T, c=digits.target)\n",
    "axs[1].set_title('t-SNE')\n",
    "axs[1].scatter(*digits_tsne.T, c=digits.target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; 2020 Agile Scientific, licensed CC-BY"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "geocomp",
   "language": "python",
   "name": "geocomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
